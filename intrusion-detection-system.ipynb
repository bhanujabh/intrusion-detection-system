{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6376134,"sourceType":"datasetVersion","datasetId":3674161}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\nprint(df.shape)\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:09.278779Z","iopub.execute_input":"2025-09-24T15:04:09.279891Z","iopub.status.idle":"2025-09-24T15:04:11.428210Z","shell.execute_reply.started":"2025-09-24T15:04:09.279854Z","shell.execute_reply":"2025-09-24T15:04:11.426754Z"}},"outputs":[{"name":"stdout","text":"(225745, 79)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    Destination Port   Flow Duration   Total Fwd Packets  \\\n0              54865               3                   2   \n1              55054             109                   1   \n2              55055              52                   1   \n3              46236              34                   1   \n4              54863               3                   2   \n\n    Total Backward Packets  Total Length of Fwd Packets  \\\n0                        0                           12   \n1                        1                            6   \n2                        1                            6   \n3                        1                            6   \n4                        0                           12   \n\n    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n0                             0                       6   \n1                             6                       6   \n2                             6                       6   \n3                             6                       6   \n4                             0                       6   \n\n    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n0                       6                      6.0                     0.0   \n1                       6                      6.0                     0.0   \n2                       6                      6.0                     0.0   \n3                       6                      6.0                     0.0   \n4                       6                      6.0                     0.0   \n\n   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n0  ...                     20          0.0          0.0            0   \n1  ...                     20          0.0          0.0            0   \n2  ...                     20          0.0          0.0            0   \n3  ...                     20          0.0          0.0            0   \n4  ...                     20          0.0          0.0            0   \n\n    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n0            0        0.0        0.0          0          0  BENIGN  \n1            0        0.0        0.0          0          0  BENIGN  \n2            0        0.0        0.0          0          0  BENIGN  \n3            0        0.0        0.0          0          0  BENIGN  \n4            0        0.0        0.0          0          0  BENIGN  \n\n[5 rows x 79 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Destination Port</th>\n      <th>Flow Duration</th>\n      <th>Total Fwd Packets</th>\n      <th>Total Backward Packets</th>\n      <th>Total Length of Fwd Packets</th>\n      <th>Total Length of Bwd Packets</th>\n      <th>Fwd Packet Length Max</th>\n      <th>Fwd Packet Length Min</th>\n      <th>Fwd Packet Length Mean</th>\n      <th>Fwd Packet Length Std</th>\n      <th>...</th>\n      <th>min_seg_size_forward</th>\n      <th>Active Mean</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54865</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>BENIGN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55054</td>\n      <td>109</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>BENIGN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55055</td>\n      <td>52</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>BENIGN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>46236</td>\n      <td>34</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>BENIGN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54863</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>BENIGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 79 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install boruta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:28.173068Z","iopub.execute_input":"2025-09-24T15:04:28.173423Z","iopub.status.idle":"2025-09-24T15:04:32.260801Z","shell.execute_reply.started":"2025-09-24T15:04:28.173391Z","shell.execute_reply":"2025-09-24T15:04:32.259468Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: boruta in /usr/local/lib/python3.11/dist-packages (0.4.3)\nRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from boruta) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from boruta) (1.2.2)\nRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from boruta) (1.15.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.10.4->boruta) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->boruta) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->boruta) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10.4->boruta) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.10.4->boruta) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.10.4->boruta) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.10.4->boruta) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.10.4->boruta) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:37.293842Z","iopub.execute_input":"2025-09-24T15:04:37.294226Z","iopub.status.idle":"2025-09-24T15:04:37.303313Z","shell.execute_reply.started":"2025-09-24T15:04:37.294194Z","shell.execute_reply":"2025-09-24T15:04:37.302175Z"}},"outputs":[{"name":"stdout","text":"Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n       ' Total Backward Packets', 'Total Length of Fwd Packets',\n       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min',\n       ' Label'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X = df.drop(columns=[' Label'])\ny = df[' Label']\n\nfrom sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)\n\nX = X.fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:40.945662Z","iopub.execute_input":"2025-09-24T15:04:40.946488Z","iopub.status.idle":"2025-09-24T15:04:41.901395Z","shell.execute_reply.started":"2025-09-24T15:04:40.946450Z","shell.execute_reply":"2025-09-24T15:04:41.900009Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\n\n# Replace inf and -inf with NaN\nX = X.replace([np.inf, -np.inf], np.nan)\n\n# Fill NaN with 0 (or column mean if you prefer)\nX = X.fillna(0)\n\n# Also clip very large values to a reasonable range\nX = np.clip(X, -1e10, 1e10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:44.922657Z","iopub.execute_input":"2025-09-24T15:04:44.923134Z","iopub.status.idle":"2025-09-24T15:04:45.407659Z","shell.execute_reply.started":"2025-09-24T15:04:44.923100Z","shell.execute_reply":"2025-09-24T15:04:45.406525Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from boruta import BorutaPy\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n\nboruta_selector = BorutaPy(\n    rf, \n    n_estimators='auto', \n    verbose=2, \n    random_state=42\n)\n\nboruta_selector.fit(X.values, y)\n\nselected_features = X.columns[boruta_selector.support_].to_list()\n# Save to CSV for reuse\npd.Series(selected_features).to_csv(\"selected_features.csv\", index=False)\n\nprint(\"Selected Features saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:04:49.251874Z","iopub.execute_input":"2025-09-24T15:04:49.252257Z","iopub.status.idle":"2025-09-24T16:04:49.241420Z","shell.execute_reply.started":"2025-09-24T15:04:49.252227Z","shell.execute_reply":"2025-09-24T16:04:49.240171Z"}},"outputs":[{"name":"stdout","text":"Iteration: \t1 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t2 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t3 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t4 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t5 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t6 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t7 / 100\nConfirmed: \t0\nTentative: \t78\nRejected: \t0\nIteration: \t8 / 100\nConfirmed: \t60\nTentative: \t6\nRejected: \t12\nIteration: \t9 / 100\nConfirmed: \t60\nTentative: \t6\nRejected: \t12\nIteration: \t10 / 100\nConfirmed: \t60\nTentative: \t6\nRejected: \t12\nIteration: \t11 / 100\nConfirmed: \t60\nTentative: \t6\nRejected: \t12\nIteration: \t12 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t13 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t14 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t15 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t16 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t17 / 100\nConfirmed: \t61\nTentative: \t5\nRejected: \t12\nIteration: \t18 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t19 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t20 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t21 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t22 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t23 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t24 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t25 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t26 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t27 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t28 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t29 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t30 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t31 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t32 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t33 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t34 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t35 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t36 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t37 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t38 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t39 / 100\nConfirmed: \t61\nTentative: \t4\nRejected: \t13\nIteration: \t40 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t41 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t42 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t43 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t44 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t45 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t46 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t47 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t48 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t49 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t50 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t51 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t52 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t53 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t54 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t55 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t56 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t57 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t58 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t59 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t60 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t61 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t62 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t63 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t64 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t65 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t66 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t67 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t68 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t69 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t70 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t71 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t72 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t73 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t74 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t75 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t76 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t77 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t78 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t79 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t80 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t81 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t82 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t83 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t84 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t85 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t86 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t87 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t88 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t89 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t90 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t91 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t92 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t93 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t94 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t95 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t96 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t97 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t98 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\nIteration: \t99 / 100\nConfirmed: \t62\nTentative: \t3\nRejected: \t13\n\n\nBorutaPy finished running.\n\nIteration: \t100 / 100\nConfirmed: \t62\nTentative: \t1\nRejected: \t15\nSelected Features saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Reload saved features\nselected_features = pd.read_csv(\"selected_features.csv\", header=None)[0].tolist()\nX_selected = df[selected_features]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_selected = X[selected_features]\n\nprint(\"Shape before:\", X.shape)\nprint(\"Shape after:\", X_selected.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:05:48.564783Z","iopub.execute_input":"2025-09-24T16:05:48.565754Z","iopub.status.idle":"2025-09-24T16:05:48.744101Z","shell.execute_reply.started":"2025-09-24T16:05:48.565716Z","shell.execute_reply":"2025-09-24T16:05:48.742986Z"}},"outputs":[{"name":"stdout","text":"Shape before: (225745, 78)\nShape after: (225745, 62)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n# Scale features for NN models\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_selected)\n\n# Encode labels (0,1,... for classes)\ny = LabelEncoder().fit_transform(y)\n\nprint(\"Final dataset shape:\", X_scaled.shape, y.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:05:55.512749Z","iopub.execute_input":"2025-09-24T16:05:55.513781Z","iopub.status.idle":"2025-09-24T16:05:56.327024Z","shell.execute_reply.started":"2025-09-24T16:05:55.513736Z","shell.execute_reply":"2025-09-24T16:05:56.325836Z"}},"outputs":[{"name":"stdout","text":"Final dataset shape: (225745, 62) (225745,)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Reduce to 50k samples for faster experiments\nX_small, _, y_small, _ = train_test_split(X_scaled, y, train_size=50000, stratify=y, random_state=42)\n\n# Split train/val/test\nX_train_full, X_test, y_train_full, y_test = train_test_split(X_small, y_small, test_size=0.2, stratify=y_small, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42)\n\nprint(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:05:59.873535Z","iopub.execute_input":"2025-09-24T16:05:59.873854Z","iopub.status.idle":"2025-09-24T16:06:00.236009Z","shell.execute_reply.started":"2025-09-24T16:05:59.873824Z","shell.execute_reply":"2025-09-24T16:06:00.235012Z"}},"outputs":[{"name":"stdout","text":"Train: (32000, 62) Val: (8000, 62) Test: (10000, 62)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# First split into train+val and test\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# Now split train into train and validation\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n)\n\nprint(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:06:03.705280Z","iopub.execute_input":"2025-09-24T16:06:03.705611Z","iopub.status.idle":"2025-09-24T16:06:04.102373Z","shell.execute_reply.started":"2025-09-24T16:06:03.705586Z","shell.execute_reply":"2025-09-24T16:06:04.101512Z"}},"outputs":[{"name":"stdout","text":"Train: (144476, 62) Val: (36120, 62) Test: (45149, 62)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Required imports\nimport numpy as np, random, time, os\nimport pandas as pd\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.model_selection import train_test_split\nimport torch, torch.nn as nn, torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# -------------------------\n# Determinism helper\n# -------------------------\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# -------------------------\n# Focal Loss\n# -------------------------\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    def forward(self, inputs, targets):\n        # inputs: logits (batch, C); targets: (batch,)\n        ce = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce)\n        loss = self.alpha * (1 - pt) ** self.gamma * ce\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        return loss\n\n# -------------------------\n# Encoders (return embedding vector)\n# -------------------------\nclass CNNEncoder(nn.Module):\n    def __init__(self, input_dim, emb_dim=128):\n        super().__init__()\n        # we'll treat features as a 1D \"sequence\" of length=input_dim with 1 channel\n        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n        self.pool = nn.AdaptiveMaxPool1d(1)\n        self.fc = nn.Linear(128, emb_dim)\n    def forward(self, x):\n        # x: [batch, input_dim]\n        x = x.unsqueeze(1)                # [batch, 1, input_dim]\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x).squeeze(-1)      # [batch, 128]\n        return self.fc(x)                 # [batch, emb_dim]\n\nclass GRUEncoder(nn.Module):\n    def __init__(self, input_dim, emb_dim=128):\n        super().__init__()\n        # interpret each sample as sequence length = input_dim, features=1\n        self.gru = nn.GRU(input_size=1, hidden_size=128, batch_first=True)\n        self.fc = nn.Linear(128, emb_dim)\n    def forward(self, x):\n        # x: [batch, input_dim]\n        x = x.unsqueeze(-1)               # [batch, seq=input_dim, 1]\n        _, h = self.gru(x)                # h: [1, batch, 128]\n        h = h.squeeze(0)\n        return self.fc(h)                 # [batch, emb_dim]\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, input_dim, emb_dim=128, nheads=4, nlayers=2):\n        super().__init__()\n        # embed each feature into a d_model vector\n        d_model = 128\n        self.embed = nn.Linear(1, d_model)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nheads, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=nlayers)\n        self.pool_fc = nn.Linear(d_model, emb_dim)\n    def forward(self, x):\n        # x: [batch, input_dim]\n        x = x.unsqueeze(-1)               # [batch, seq=input_dim, 1]\n        x = self.embed(x)                 # [batch, seq, d_model]\n        x = self.transformer(x)           # [batch, seq, d_model]\n        x = x.mean(dim=1)                 # global average pool over seq\n        return self.pool_fc(x)            # [batch, emb_dim]\n\n# -------------------------\n# Combined model builder\n# -------------------------\nclass CombinedModel(nn.Module):\n    def __init__(self, encoders, emb_dim=128, num_classes=2, dropout=0.3):\n        \"\"\"\n        encoders: list of encoder modules (nn.Module). Each encoder outputs an embedding vector.\n        \"\"\"\n        super().__init__()\n        self.encoders = nn.ModuleList(encoders)\n        total_emb = emb_dim * len(encoders)\n        self.head = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(total_emb, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(256, num_classes)\n        )\n    def forward(self, x):\n        embs = [enc(x) for enc in self.encoders]  # each [batch, emb_dim]\n        concat = torch.cat(embs, dim=1)           # [batch, total_emb]\n        return self.head(concat)                  # logits\n\n# -------------------------\n# Training & evaluation utilities\n# -------------------------\ndef train_one_epoch(model, loader, optimizer, loss_fn, device):\n    model.train()\n    epoch_loss = 0.0\n    for xb, yb in loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = loss_fn(logits, yb)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item() * xb.size(0)\n    return epoch_loss / len(loader.dataset)\n\ndef eval_model(model, loader, device):\n    model.eval()\n    preds, trues = [], []\n    with torch.no_grad():\n        for xb, yb in loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            trues.extend(yb.numpy())\n    return np.array(preds), np.array(trues)\n\ndef compute_metrics(y_true, y_pred):\n    out = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0)\n    }\n    return out\n\n# -------------------------\n# Experiment runner (runs combos)\n# -------------------------\ndef run_experiment_combo(X_train, y_train, X_val, y_val, X_test, y_test,\n                         combo_name, encoder_classes, input_dim, num_classes,\n                         seed=42, device='cuda' if torch.cuda.is_available() else 'cpu',\n                         epochs=20, batch_size=256, lr=1e-3, emb_dim=128):\n    set_seed(seed)\n    device = torch.device(device)\n    # instantiate encoders\n    encs = [cls(input_dim=input_dim, emb_dim=emb_dim) for cls in encoder_classes]\n    model = CombinedModel(encs, emb_dim=emb_dim, num_classes=num_classes).to(device)\n    loss_fn = FocalLoss(alpha=1.0, gamma=2.0)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    # DataLoaders\n    tr_loader = DataLoader(TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n                                        torch.tensor(y_train, dtype=torch.long)),\n                           batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n                                         torch.tensor(y_val, dtype=torch.long)),\n                           batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n                                          torch.tensor(y_test, dtype=torch.long)),\n                            batch_size=batch_size, shuffle=False)\n\n    best_val_f1 = -1.0\n    best_state = None\n    history = []\n    start = time.time()\n    for ep in range(epochs):\n        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, device)\n        preds_val, trues_val = eval_model(model, val_loader, device)\n        m = compute_metrics(trues_val, preds_val)\n        history.append({'epoch': ep+1, 'train_loss': tr_loss, **m})\n        if m['f1_macro'] > best_val_f1:\n            best_val_f1 = m['f1_macro']\n            best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n\n    # load best and eval on test\n    model.load_state_dict(best_state)\n    preds_test, trues_test = eval_model(model, test_loader, device)\n    test_metrics = compute_metrics(trues_test, preds_test)\n    elapsed = time.time() - start\n\n    result = {\n        'combo': combo_name,\n        'seed': seed,\n        'train_samples': len(X_train),\n        'val_samples': len(X_val),\n        'test_samples': len(X_test),\n        'epochs_trained': epochs,\n        'time_s': elapsed,\n        **test_metrics\n    }\n    return result, history\n\n# -------------------------\n# How to run all combos\n# -------------------------\ndef run_all_combinations(X_train, y_train, X_val, y_val, X_test, y_test, input_dim, num_classes,\n                         seeds=[42], out_csv='ablation_results.csv', combos_to_run=None):\n    all_combos = {\n        'CNN': [CNNEncoder],\n        'GRU': [GRUEncoder],\n        'Transformer': [TransformerEncoder],\n        'CNN+GRU': [CNNEncoder, GRUEncoder],\n        'CNN+Transformer': [CNNEncoder, TransformerEncoder],\n        'GRU+Transformer': [GRUEncoder, TransformerEncoder],\n        'CNN+GRU+Transformer': [CNNEncoder, GRUEncoder, TransformerEncoder]\n    }\n    if combos_to_run is None:\n        combos = all_combos\n    else:\n        combos = {k: all_combos[k] for k in combos_to_run if k in all_combos}\n    \n    results = []\n    for seed in seeds:\n        for name, enc_list in combos.items():\n            print(f\"Running {name} (seed {seed}) ...\")\n            res, hist = run_experiment_combo(\n                X_train, y_train, X_val, y_val, X_test, y_test,\n                combo_name=name,\n                encoder_classes=enc_list,\n                input_dim=input_dim,\n                num_classes=num_classes,\n                seed=seed\n            )\n            results.append(res)\n            pd.DataFrame(hist).to_csv(f'history_{name}_seed{seed}.csv', index=False)\n            # append results incrementally\n            pd.DataFrame(results).to_csv(out_csv, mode='a', header=not os.path.exists(out_csv), index=False)\n    return pd.DataFrame(results)\n\n\n# -------------------------\n# Example usage (assuming you have X and y prepared)\n# -------------------------\n# 1) Prepare data splits (stratify)\n# X_scaled and y (numpy arrays)\n# X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n# X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42)\n\n# 2) Run\n# df_results = run_all_combinations(X_train, y_train, X_val, y_val, X_test, y_test,\n#                                  input_dim=X_train.shape[1], num_classes=len(np.unique(y)), seeds=[42, 7, 123])\n# print(df_results)\n# df_results.to_csv('ablation_summary.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:06:31.180593Z","iopub.execute_input":"2025-09-24T16:06:31.181129Z","iopub.status.idle":"2025-09-24T16:06:31.219013Z","shell.execute_reply.started":"2025-09-24T16:06:31.181100Z","shell.execute_reply":"2025-09-24T16:06:31.217980Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df_results_cnn = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['CNN'],\n    out_csv='results_partial.csv'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:06:43.520859Z","iopub.execute_input":"2025-09-24T16:06:43.521236Z"}},"outputs":[{"name":"stdout","text":"Running CNN (seed 42) ...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"df_results_gru = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['GRU'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results_transformer = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['Transformer'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results_cnn_gru = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['CNN+GRU'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf_results_cnn_transformer = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['CNN+Transformer'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results_gru_transformer = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['GRU+Transformer'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run three-model hybrid\ndf_results_all = run_all_combinations(\n    X_train, y_train, X_val, y_val, X_test, y_test,\n    input_dim=X_train.shape[1],\n    num_classes=len(np.unique(y)),\n    seeds=[42],\n    combos_to_run=['CNN+GRU+Transformer'],\n    out_csv='results_partial.csv'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}